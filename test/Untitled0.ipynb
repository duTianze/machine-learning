{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duTianze/machine-learning/blob/master/test/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "sdhPHu1LqjAG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wEGjt0rnq0vJ",
        "colab_type": "code",
        "outputId": "15b5e5b7-2a44-4a13-aae2-65fff333b51a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "#os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
        "import time\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.contrib.eager.python.examples.rnn_colorbot.rnn_colorbot import loss\n",
        "\n",
        "def load_data():\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    number = 10000\n",
        "    x_train = x_train[0:number]\n",
        "    y_train = y_train[0:number]\n",
        "    \n",
        "    x_train = x_train.reshape(number, 28*28)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 28*28)\n",
        "    \n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    \n",
        "    y_train = np_utils.to_categorical(y_train, 10)\n",
        "    y_test = np_utils.to_categorical(y_test, 10)\n",
        "    \n",
        "    x_train = x_train / 255\n",
        "    x_test = x_test / 255\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "    \n",
        "(x_train, y_train), (x_test, y_test) = load_data()\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(input_dim=28*28, units=633, activation='sigmoid'))\n",
        "model.add(Dense(units=689, activation='sigmoid'))\n",
        "model.add(Dense(units=689, activation='sigmoid'))\n",
        "\n",
        "for i in range(10):\n",
        "    model.add(Dense(units=689, activation='sigmoid'))\n",
        "\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='mse', optimizer=SGD(lr=0.1), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "print(\"Timing inference...\")\n",
        "\n",
        "start = time.time()\n",
        "model.fit(x_train, y_train, batch_size=100, epochs=20)\n",
        "\n",
        "print(\"Ran in {} seconds\".format(time.time() - start))\n",
        "\n",
        "result = model.evaluate(x_test, y_test)\n",
        "print('\\nTest Acc:', result[1])\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Timing inference...\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 2s 209us/step - loss: 0.0904 - acc: 0.1082\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 1s 148us/step - loss: 0.0900 - acc: 0.1100\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 1s 148us/step - loss: 0.0900 - acc: 0.1097\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 1s 146us/step - loss: 0.0900 - acc: 0.1078\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 1s 145us/step - loss: 0.0900 - acc: 0.1098\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 1s 146us/step - loss: 0.0900 - acc: 0.1096\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 1s 143us/step - loss: 0.0900 - acc: 0.1098\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 1s 144us/step - loss: 0.0900 - acc: 0.1093\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 1s 144us/step - loss: 0.0900 - acc: 0.1076\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 1s 144us/step - loss: 0.0900 - acc: 0.1104\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 1s 144us/step - loss: 0.0900 - acc: 0.1100\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 1s 143us/step - loss: 0.0900 - acc: 0.1125\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 1s 143us/step - loss: 0.0900 - acc: 0.1111\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 1s 144us/step - loss: 0.0900 - acc: 0.1096\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 1s 142us/step - loss: 0.0900 - acc: 0.1106\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 1s 144us/step - loss: 0.0900 - acc: 0.1086\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 1s 143us/step - loss: 0.0900 - acc: 0.1091\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 1s 144us/step - loss: 0.0900 - acc: 0.1092\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 1s 143us/step - loss: 0.0900 - acc: 0.1109\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 1s 143us/step - loss: 0.0900 - acc: 0.1092\n",
            "Ran in 30.122100353240967 seconds\n",
            "10000/10000 [==============================] - 1s 102us/step\n",
            "\n",
            "Test Acc: 0.1135\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}